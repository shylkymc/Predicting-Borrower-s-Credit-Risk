{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BORROWER'S CREDIT RISK MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, my aim is to create a borrower's credit risk model for lenders. The Lending Club releases all data which contains approved or declined loan applications. You can download the data sets from this [website](https://www.lendingclub.com/auth/login?login_url=%2Fstatistics%2Fadditional-statistics%3F). Let's start with exploring and cleaning data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening and Clearing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I imported the Pandas library especially to use on my exploring and cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                1077501\n",
       "member_id                      1.2966e+06\n",
       "loan_amnt                            5000\n",
       "funded_amnt                          5000\n",
       "funded_amnt_inv                      4975\n",
       "term                            36 months\n",
       "int_rate                           10.65%\n",
       "installment                        162.87\n",
       "grade                                   B\n",
       "sub_grade                              B2\n",
       "emp_title                             NaN\n",
       "emp_length                      10+ years\n",
       "home_ownership                       RENT\n",
       "annual_inc                          24000\n",
       "verification_status              Verified\n",
       "issue_d                          Dec-2011\n",
       "loan_status                    Fully Paid\n",
       "pymnt_plan                              n\n",
       "purpose                       credit_card\n",
       "title                            Computer\n",
       "zip_code                            860xx\n",
       "addr_state                             AZ\n",
       "dti                                 27.65\n",
       "delinq_2yrs                             0\n",
       "earliest_cr_line                 Jan-1985\n",
       "inq_last_6mths                          1\n",
       "open_acc                                3\n",
       "pub_rec                                 0\n",
       "revol_bal                           13648\n",
       "revol_util                          83.7%\n",
       "total_acc                               9\n",
       "initial_list_status                     f\n",
       "out_prncp                               0\n",
       "out_prncp_inv                           0\n",
       "total_pymnt                       5863.16\n",
       "total_pymnt_inv                   5833.84\n",
       "total_rec_prncp                      5000\n",
       "total_rec_int                      863.16\n",
       "total_rec_late_fee                      0\n",
       "recoveries                              0\n",
       "collection_recovery_fee                 0\n",
       "last_pymnt_d                     Jan-2015\n",
       "last_pymnt_amnt                    171.62\n",
       "last_credit_pull_d               Jun-2016\n",
       "collections_12_mths_ex_med              0\n",
       "policy_code                             1\n",
       "application_type               INDIVIDUAL\n",
       "acc_now_delinq                          0\n",
       "chargeoff_within_12_mths                0\n",
       "delinq_amnt                             0\n",
       "pub_rec_bankruptcies                    0\n",
       "tax_liens                               0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans= pd.read_csv('loans_2007.csv')\n",
    "loans.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42538 entries, 0 to 42537\n",
      "Data columns (total 52 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          42538 non-null  object \n",
      " 1   member_id                   42535 non-null  float64\n",
      " 2   loan_amnt                   42535 non-null  float64\n",
      " 3   funded_amnt                 42535 non-null  float64\n",
      " 4   funded_amnt_inv             42535 non-null  float64\n",
      " 5   term                        42535 non-null  object \n",
      " 6   int_rate                    42535 non-null  object \n",
      " 7   installment                 42535 non-null  float64\n",
      " 8   grade                       42535 non-null  object \n",
      " 9   sub_grade                   42535 non-null  object \n",
      " 10  emp_title                   39909 non-null  object \n",
      " 11  emp_length                  41423 non-null  object \n",
      " 12  home_ownership              42535 non-null  object \n",
      " 13  annual_inc                  42531 non-null  float64\n",
      " 14  verification_status         42535 non-null  object \n",
      " 15  issue_d                     42535 non-null  object \n",
      " 16  loan_status                 42535 non-null  object \n",
      " 17  pymnt_plan                  42535 non-null  object \n",
      " 18  purpose                     42535 non-null  object \n",
      " 19  title                       42522 non-null  object \n",
      " 20  zip_code                    42535 non-null  object \n",
      " 21  addr_state                  42535 non-null  object \n",
      " 22  dti                         42535 non-null  float64\n",
      " 23  delinq_2yrs                 42506 non-null  float64\n",
      " 24  earliest_cr_line            42506 non-null  object \n",
      " 25  inq_last_6mths              42506 non-null  float64\n",
      " 26  open_acc                    42506 non-null  float64\n",
      " 27  pub_rec                     42506 non-null  float64\n",
      " 28  revol_bal                   42535 non-null  float64\n",
      " 29  revol_util                  42445 non-null  object \n",
      " 30  total_acc                   42506 non-null  float64\n",
      " 31  initial_list_status         42535 non-null  object \n",
      " 32  out_prncp                   42535 non-null  float64\n",
      " 33  out_prncp_inv               42535 non-null  float64\n",
      " 34  total_pymnt                 42535 non-null  float64\n",
      " 35  total_pymnt_inv             42535 non-null  float64\n",
      " 36  total_rec_prncp             42535 non-null  float64\n",
      " 37  total_rec_int               42535 non-null  float64\n",
      " 38  total_rec_late_fee          42535 non-null  float64\n",
      " 39  recoveries                  42535 non-null  float64\n",
      " 40  collection_recovery_fee     42535 non-null  float64\n",
      " 41  last_pymnt_d                42452 non-null  object \n",
      " 42  last_pymnt_amnt             42535 non-null  float64\n",
      " 43  last_credit_pull_d          42531 non-null  object \n",
      " 44  collections_12_mths_ex_med  42390 non-null  float64\n",
      " 45  policy_code                 42535 non-null  float64\n",
      " 46  application_type            42535 non-null  object \n",
      " 47  acc_now_delinq              42506 non-null  float64\n",
      " 48  chargeoff_within_12_mths    42390 non-null  float64\n",
      " 49  delinq_amnt                 42506 non-null  float64\n",
      " 50  pub_rec_bankruptcies        41170 non-null  float64\n",
      " 51  tax_liens                   42430 non-null  float64\n",
      "dtypes: float64(30), object(22)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>last_pymnt_amnt</th>\n",
       "      <th>last_credit_pull_d</th>\n",
       "      <th>collections_12_mths_ex_med</th>\n",
       "      <th>policy_code</th>\n",
       "      <th>application_type</th>\n",
       "      <th>acc_now_delinq</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077501</td>\n",
       "      <td>1296599.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>10.65%</td>\n",
       "      <td>162.87</td>\n",
       "      <td>B</td>\n",
       "      <td>B2</td>\n",
       "      <td>...</td>\n",
       "      <td>171.62</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1077430</td>\n",
       "      <td>1314167.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>15.27%</td>\n",
       "      <td>59.83</td>\n",
       "      <td>C</td>\n",
       "      <td>C4</td>\n",
       "      <td>...</td>\n",
       "      <td>119.66</td>\n",
       "      <td>Sep-2013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1077175</td>\n",
       "      <td>1313524.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>15.96%</td>\n",
       "      <td>84.33</td>\n",
       "      <td>C</td>\n",
       "      <td>C5</td>\n",
       "      <td>...</td>\n",
       "      <td>649.91</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1076863</td>\n",
       "      <td>1277178.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.49%</td>\n",
       "      <td>339.31</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "      <td>...</td>\n",
       "      <td>357.48</td>\n",
       "      <td>Apr-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075358</td>\n",
       "      <td>1311748.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>12.69%</td>\n",
       "      <td>67.79</td>\n",
       "      <td>B</td>\n",
       "      <td>B5</td>\n",
       "      <td>...</td>\n",
       "      <td>67.79</td>\n",
       "      <td>Jun-2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42533</th>\n",
       "      <td>72176</td>\n",
       "      <td>70868.0</td>\n",
       "      <td>2525.0</td>\n",
       "      <td>2525.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>9.33%</td>\n",
       "      <td>80.69</td>\n",
       "      <td>B</td>\n",
       "      <td>B3</td>\n",
       "      <td>...</td>\n",
       "      <td>82.03</td>\n",
       "      <td>May-2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42534</th>\n",
       "      <td>71623</td>\n",
       "      <td>70735.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>8.38%</td>\n",
       "      <td>204.84</td>\n",
       "      <td>A</td>\n",
       "      <td>A5</td>\n",
       "      <td>...</td>\n",
       "      <td>205.32</td>\n",
       "      <td>Aug-2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42535</th>\n",
       "      <td>70686</td>\n",
       "      <td>70681.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>7.75%</td>\n",
       "      <td>156.11</td>\n",
       "      <td>A</td>\n",
       "      <td>A3</td>\n",
       "      <td>...</td>\n",
       "      <td>156.39</td>\n",
       "      <td>Feb-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>INDIVIDUAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42536</th>\n",
       "      <td>Total amount funded in policy code 1: 471701350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42537</th>\n",
       "      <td>Total amount funded in policy code 2: 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42538 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    id  member_id  loan_amnt  \\\n",
       "0                                              1077501  1296599.0     5000.0   \n",
       "1                                              1077430  1314167.0     2500.0   \n",
       "2                                              1077175  1313524.0     2400.0   \n",
       "3                                              1076863  1277178.0    10000.0   \n",
       "4                                              1075358  1311748.0     3000.0   \n",
       "...                                                ...        ...        ...   \n",
       "42533                                            72176    70868.0     2525.0   \n",
       "42534                                            71623    70735.0     6500.0   \n",
       "42535                                            70686    70681.0     5000.0   \n",
       "42536  Total amount funded in policy code 1: 471701350        NaN        NaN   \n",
       "42537          Total amount funded in policy code 2: 0        NaN        NaN   \n",
       "\n",
       "       funded_amnt  funded_amnt_inv        term int_rate  installment grade  \\\n",
       "0           5000.0           4975.0   36 months   10.65%       162.87     B   \n",
       "1           2500.0           2500.0   60 months   15.27%        59.83     C   \n",
       "2           2400.0           2400.0   36 months   15.96%        84.33     C   \n",
       "3          10000.0          10000.0   36 months   13.49%       339.31     C   \n",
       "4           3000.0           3000.0   60 months   12.69%        67.79     B   \n",
       "...            ...              ...         ...      ...          ...   ...   \n",
       "42533       2525.0            225.0   36 months    9.33%        80.69     B   \n",
       "42534       6500.0              0.0   36 months    8.38%       204.84     A   \n",
       "42535       5000.0              0.0   36 months    7.75%       156.11     A   \n",
       "42536          NaN              NaN         NaN      NaN          NaN   NaN   \n",
       "42537          NaN              NaN         NaN      NaN          NaN   NaN   \n",
       "\n",
       "      sub_grade  ... last_pymnt_amnt last_credit_pull_d  \\\n",
       "0            B2  ...          171.62           Jun-2016   \n",
       "1            C4  ...          119.66           Sep-2013   \n",
       "2            C5  ...          649.91           Jun-2016   \n",
       "3            C1  ...          357.48           Apr-2016   \n",
       "4            B5  ...           67.79           Jun-2016   \n",
       "...         ...  ...             ...                ...   \n",
       "42533        B3  ...           82.03           May-2007   \n",
       "42534        A5  ...          205.32           Aug-2007   \n",
       "42535        A3  ...          156.39           Feb-2015   \n",
       "42536       NaN  ...             NaN                NaN   \n",
       "42537       NaN  ...             NaN                NaN   \n",
       "\n",
       "      collections_12_mths_ex_med  policy_code application_type acc_now_delinq  \\\n",
       "0                            0.0          1.0       INDIVIDUAL            0.0   \n",
       "1                            0.0          1.0       INDIVIDUAL            0.0   \n",
       "2                            0.0          1.0       INDIVIDUAL            0.0   \n",
       "3                            0.0          1.0       INDIVIDUAL            0.0   \n",
       "4                            0.0          1.0       INDIVIDUAL            0.0   \n",
       "...                          ...          ...              ...            ...   \n",
       "42533                        NaN          1.0       INDIVIDUAL            NaN   \n",
       "42534                        NaN          1.0       INDIVIDUAL            NaN   \n",
       "42535                        NaN          1.0       INDIVIDUAL            NaN   \n",
       "42536                        NaN          NaN              NaN            NaN   \n",
       "42537                        NaN          NaN              NaN            NaN   \n",
       "\n",
       "      chargeoff_within_12_mths delinq_amnt pub_rec_bankruptcies tax_liens  \n",
       "0                          0.0         0.0                  0.0       0.0  \n",
       "1                          0.0         0.0                  0.0       0.0  \n",
       "2                          0.0         0.0                  0.0       0.0  \n",
       "3                          0.0         0.0                  0.0       0.0  \n",
       "4                          0.0         0.0                  0.0       0.0  \n",
       "...                        ...         ...                  ...       ...  \n",
       "42533                      NaN         NaN                  NaN       NaN  \n",
       "42534                      NaN         NaN                  NaN       NaN  \n",
       "42535                      NaN         NaN                  NaN       NaN  \n",
       "42536                      NaN         NaN                  NaN       NaN  \n",
       "42537                      NaN         NaN                  NaN       NaN  \n",
       "\n",
       "[42538 rows x 52 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42538 entries, 0 to 42537\n",
      "Data columns (total 52 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          42538 non-null  object \n",
      " 1   member_id                   42535 non-null  float64\n",
      " 2   loan_amnt                   42535 non-null  float64\n",
      " 3   funded_amnt                 42535 non-null  float64\n",
      " 4   funded_amnt_inv             42535 non-null  float64\n",
      " 5   term                        42535 non-null  object \n",
      " 6   int_rate                    42535 non-null  object \n",
      " 7   installment                 42535 non-null  float64\n",
      " 8   grade                       42535 non-null  object \n",
      " 9   sub_grade                   42535 non-null  object \n",
      " 10  emp_title                   39909 non-null  object \n",
      " 11  emp_length                  41423 non-null  object \n",
      " 12  home_ownership              42535 non-null  object \n",
      " 13  annual_inc                  42531 non-null  float64\n",
      " 14  verification_status         42535 non-null  object \n",
      " 15  issue_d                     42535 non-null  object \n",
      " 16  loan_status                 42535 non-null  object \n",
      " 17  pymnt_plan                  42535 non-null  object \n",
      " 18  purpose                     42535 non-null  object \n",
      " 19  title                       42522 non-null  object \n",
      " 20  zip_code                    42535 non-null  object \n",
      " 21  addr_state                  42535 non-null  object \n",
      " 22  dti                         42535 non-null  float64\n",
      " 23  delinq_2yrs                 42506 non-null  float64\n",
      " 24  earliest_cr_line            42506 non-null  object \n",
      " 25  inq_last_6mths              42506 non-null  float64\n",
      " 26  open_acc                    42506 non-null  float64\n",
      " 27  pub_rec                     42506 non-null  float64\n",
      " 28  revol_bal                   42535 non-null  float64\n",
      " 29  revol_util                  42445 non-null  object \n",
      " 30  total_acc                   42506 non-null  float64\n",
      " 31  initial_list_status         42535 non-null  object \n",
      " 32  out_prncp                   42535 non-null  float64\n",
      " 33  out_prncp_inv               42535 non-null  float64\n",
      " 34  total_pymnt                 42535 non-null  float64\n",
      " 35  total_pymnt_inv             42535 non-null  float64\n",
      " 36  total_rec_prncp             42535 non-null  float64\n",
      " 37  total_rec_int               42535 non-null  float64\n",
      " 38  total_rec_late_fee          42535 non-null  float64\n",
      " 39  recoveries                  42535 non-null  float64\n",
      " 40  collection_recovery_fee     42535 non-null  float64\n",
      " 41  last_pymnt_d                42452 non-null  object \n",
      " 42  last_pymnt_amnt             42535 non-null  float64\n",
      " 43  last_credit_pull_d          42531 non-null  object \n",
      " 44  collections_12_mths_ex_med  42390 non-null  float64\n",
      " 45  policy_code                 42535 non-null  float64\n",
      " 46  application_type            42535 non-null  object \n",
      " 47  acc_now_delinq              42506 non-null  float64\n",
      " 48  chargeoff_within_12_mths    42390 non-null  float64\n",
      " 49  delinq_amnt                 42506 non-null  float64\n",
      " 50  pub_rec_bankruptcies        41170 non-null  float64\n",
      " 51  tax_liens                   42430 non-null  float64\n",
      "dtypes: float64(30), object(22)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of columns in the data set and some of them are seen as useless. I have to decide which column is useful for my prediction model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will drop some colmns which is in cols list.\n",
    "cols=['id',\n",
    "      'member_id',\n",
    "      'funded_amnt',\n",
    "      'funded_amnt_inv',\n",
    "      'grade',\n",
    "      'sub_grade',\n",
    "      'emp_title',\n",
    "      'issue_d',\n",
    "      'zip_code',\n",
    "      'out_prncp',\n",
    "      'out_prncp_inv',\n",
    "      'total_pymnt',\n",
    "      'total_pymnt_inv',\n",
    "      'total_rec_prncp',\n",
    "      'total_rec_int',\n",
    "      'total_rec_late_fee',\n",
    "      'recoveries',\n",
    "      'collection_recovery_fee',\n",
    "      'last_pymnt_d',\n",
    "      'last_pymnt_amnt'\n",
    "      \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't need the \"id\" and \"member_id\" columns. The \"grade\" and the \"sub_grade\" columns have the same information with the \"int_rate\" column. The \"emp_title\" column can be useful with additional data, but I don't have this data and it is useless for me. Only 3 of the 5 digits are visible in the \"zip_code\" column, so it is redundant. You can see the list of columns below which leak data from the future:\n",
    "<br>\n",
    "-\"funded_amnt\",\n",
    "<br>\n",
    "-\"funded_amnt_inv\",\n",
    "<br>\n",
    "-\"issue_d\",\n",
    "<br>\n",
    "-\"out_prncp\",\n",
    "<br>\n",
    "-\"out_prncp_inv\",\n",
    "<br> \n",
    "-\"out_prncp_inv\",\n",
    "<br>\n",
    "-\"total_pymnt\", \n",
    "<br>\n",
    "-\"total_pymnt_inv\", \n",
    "<br>\n",
    "-\"total_rec_prncp\", \n",
    "<br>\n",
    "-\"total_rec_int\", \n",
    "<br>\n",
    "-\"total_rec_late_fee\", \n",
    "<br>\n",
    "-\"recoveries\",\n",
    "<br>\n",
    "-\"collection_recovery_fee\",\n",
    "<br>\n",
    "-\"last_pymnt_d\", \n",
    "<br>\n",
    "-\"last_pymnt_amnt\".\n",
    "<br>\n",
    "<br>\n",
    "All of these columns have information about loans after the loans already started to be paid off. Let's drop these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans= loans.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42538 entries, 0 to 42537\n",
      "Data columns (total 32 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   loan_amnt                   42535 non-null  float64\n",
      " 1   term                        42535 non-null  object \n",
      " 2   int_rate                    42535 non-null  object \n",
      " 3   installment                 42535 non-null  float64\n",
      " 4   emp_length                  41423 non-null  object \n",
      " 5   home_ownership              42535 non-null  object \n",
      " 6   annual_inc                  42531 non-null  float64\n",
      " 7   verification_status         42535 non-null  object \n",
      " 8   loan_status                 42535 non-null  object \n",
      " 9   pymnt_plan                  42535 non-null  object \n",
      " 10  purpose                     42535 non-null  object \n",
      " 11  title                       42522 non-null  object \n",
      " 12  addr_state                  42535 non-null  object \n",
      " 13  dti                         42535 non-null  float64\n",
      " 14  delinq_2yrs                 42506 non-null  float64\n",
      " 15  earliest_cr_line            42506 non-null  object \n",
      " 16  inq_last_6mths              42506 non-null  float64\n",
      " 17  open_acc                    42506 non-null  float64\n",
      " 18  pub_rec                     42506 non-null  float64\n",
      " 19  revol_bal                   42535 non-null  float64\n",
      " 20  revol_util                  42445 non-null  object \n",
      " 21  total_acc                   42506 non-null  float64\n",
      " 22  initial_list_status         42535 non-null  object \n",
      " 23  last_credit_pull_d          42531 non-null  object \n",
      " 24  collections_12_mths_ex_med  42390 non-null  float64\n",
      " 25  policy_code                 42535 non-null  float64\n",
      " 26  application_type            42535 non-null  object \n",
      " 27  acc_now_delinq              42506 non-null  float64\n",
      " 28  chargeoff_within_12_mths    42390 non-null  float64\n",
      " 29  delinq_amnt                 42506 non-null  float64\n",
      " 30  pub_rec_bankruptcies        41170 non-null  float64\n",
      " 31  tax_liens                   42430 non-null  float64\n",
      "dtypes: float64(17), object(15)\n",
      "memory usage: 10.4+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have 32 columns to use. The 'loan_status' column shows that loan is accepted or dismissed. This column has text type values. Let's change the column type from text to numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fully Paid                                             33136\n",
       "Charged Off                                             5634\n",
       "Does not meet the credit policy. Status:Fully Paid      1988\n",
       "Current                                                  961\n",
       "Does not meet the credit policy. Status:Charged Off      761\n",
       "Late (31-120 days)                                        24\n",
       "In Grace Period                                           20\n",
       "Late (16-30 days)                                          8\n",
       "Default                                                    3\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will only use entries which have 'Charged Off', 'Fully Paid', 'Does not meet the credit policy. Status:Fully Paid' and 'Does not meet the credit policy. Status:Charged Off' values. This is because my aim is to make predictions about loans which are paid or not paid. Other values do not give proper information for my model. I will start with dropping the entries which have values out of our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans= loans[(loans['loan_status']=='Fully Paid')|(loans['loan_status']=='Charged Off')|(loans['loan_status']=='Does not meet the credit policy. Status:Fully Paid')|\n",
    "             (loans['loan_status']=='Does not meet the credit policy. Status:Charged Off')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41519, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use a binary system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_status= {'loan_status': {'Fully Paid':1, 'Charged Off':0, 'Does not meet the credit policy. Status:Fully Paid':1,\n",
    "                               'Does not meet the credit policy. Status:Charged Off':0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans= loans.replace(binary_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35124\n",
       "0     6395\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, I will drop the columns which have only one unique value. These columns are not able to give information for the prediction model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_cols=loans.columns\n",
    "drop_cols=[]\n",
    "for col in orig_cols:\n",
    "    col_series=loans[col].dropna().unique()\n",
    "    if len(col_series)==1:\n",
    "        drop_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pymnt_plan', 'initial_list_status', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'chargeoff_within_12_mths']\n"
     ]
    }
   ],
   "source": [
    "loans=loans.drop(drop_cols,axis=1)\n",
    "print(drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I will prepare the features for my prediction models. My focus is on the \"Fully Paid\", the \"Charged Off\", the \"Does not meet the credit policy. Status:Fully Paid\" and the \"Does not meet the credit policy. Status:Charged Off\" entries on the \"loan_status\" column. As you remember, my value is 1 for the \"Fully Paid\" and the \"Does not meet the credit policy. Status:Fully Paid\" entries; and 0 for the \"Charged Off\" and he \"Does not meet the credit policy. Status:Charged Off\" entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41519 entries, 0 to 42535\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   loan_amnt             41519 non-null  float64\n",
      " 1   term                  41519 non-null  object \n",
      " 2   int_rate              41519 non-null  object \n",
      " 3   installment           41519 non-null  float64\n",
      " 4   emp_length            40449 non-null  object \n",
      " 5   home_ownership        41519 non-null  object \n",
      " 6   annual_inc            41515 non-null  float64\n",
      " 7   verification_status   41519 non-null  object \n",
      " 8   loan_status           41519 non-null  int64  \n",
      " 9   purpose               41519 non-null  object \n",
      " 10  title                 41506 non-null  object \n",
      " 11  addr_state            41519 non-null  object \n",
      " 12  dti                   41519 non-null  float64\n",
      " 13  delinq_2yrs           41490 non-null  float64\n",
      " 14  earliest_cr_line      41490 non-null  object \n",
      " 15  inq_last_6mths        41490 non-null  float64\n",
      " 16  open_acc              41490 non-null  float64\n",
      " 17  pub_rec               41490 non-null  float64\n",
      " 18  revol_bal             41519 non-null  float64\n",
      " 19  revol_util            41429 non-null  object \n",
      " 20  total_acc             41490 non-null  float64\n",
      " 21  last_credit_pull_d    41515 non-null  object \n",
      " 22  acc_now_delinq        41490 non-null  float64\n",
      " 23  delinq_amnt           41490 non-null  float64\n",
      " 24  pub_rec_bankruptcies  40154 non-null  float64\n",
      " 25  tax_liens             41414 non-null  float64\n",
      "dtypes: float64(14), int64(1), object(11)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have missing values, I have to get rid of these missing values. I will detect the missing values and develop a strategy to clean them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_length              1070\n",
      "annual_inc                 4\n",
      "title                     13\n",
      "delinq_2yrs               29\n",
      "earliest_cr_line          29\n",
      "inq_last_6mths            29\n",
      "open_acc                  29\n",
      "pub_rec                   29\n",
      "revol_util                90\n",
      "total_acc                 29\n",
      "last_credit_pull_d         4\n",
      "acc_now_delinq            29\n",
      "delinq_amnt               29\n",
      "pub_rec_bankruptcies    1365\n",
      "tax_liens                105\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_count=loans.isnull().sum()\n",
    "print(null_count[null_count>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"emp_length\" column and the \"pub_rec_bankruptcies\" columns have high amounts of missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ax=sns.countplot(x='loan_status', data=loans[loans['emp_length'].isnull()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the missing values are in the \"Fully Paid\" entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"pub_rec_bankruptcies\" column will be dropped.\n",
    "#Other rows which have missing values will be dropped.\n",
    "loans=loans.drop('pub_rec_bankruptcies',axis=1)\n",
    "loans=loans.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped the \"pub_rec_bankruptcies\" column because this column won't give me predictive values. After that, I only dropped the entries from: \n",
    "<br>\n",
    "-\"emp_length\",\n",
    "<br>\n",
    "-\"title\",\n",
    "<br>\n",
    "-\"revol_util\",\n",
    "<br>\n",
    "-\"last_credit_pull_d\" columns. \n",
    "<br>\n",
    "I didn't drop these columns because I will use them on my prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40273 entries, 0 to 42478\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   loan_amnt            40273 non-null  float64\n",
      " 1   term                 40273 non-null  object \n",
      " 2   int_rate             40273 non-null  object \n",
      " 3   installment          40273 non-null  float64\n",
      " 4   emp_length           40273 non-null  object \n",
      " 5   home_ownership       40273 non-null  object \n",
      " 6   annual_inc           40273 non-null  float64\n",
      " 7   verification_status  40273 non-null  object \n",
      " 8   loan_status          40273 non-null  int64  \n",
      " 9   purpose              40273 non-null  object \n",
      " 10  title                40273 non-null  object \n",
      " 11  addr_state           40273 non-null  object \n",
      " 12  dti                  40273 non-null  float64\n",
      " 13  delinq_2yrs          40273 non-null  float64\n",
      " 14  earliest_cr_line     40273 non-null  object \n",
      " 15  inq_last_6mths       40273 non-null  float64\n",
      " 16  open_acc             40273 non-null  float64\n",
      " 17  pub_rec              40273 non-null  float64\n",
      " 18  revol_bal            40273 non-null  float64\n",
      " 19  revol_util           40273 non-null  object \n",
      " 20  total_acc            40273 non-null  float64\n",
      " 21  last_credit_pull_d   40273 non-null  object \n",
      " 22  acc_now_delinq       40273 non-null  float64\n",
      " 23  delinq_amnt          40273 non-null  float64\n",
      " 24  tax_liens            40273 non-null  float64\n",
      "dtypes: float64(13), int64(1), object(11)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    34153\n",
       "0     6120\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans.loan_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    13\n",
      "object     11\n",
      "int64       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need only numerical data types to use. I will explore the columns which are object data type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                     36 months\n",
      "int_rate                    10.65%\n",
      "emp_length               10+ years\n",
      "home_ownership                RENT\n",
      "verification_status       Verified\n",
      "purpose                credit_card\n",
      "title                     Computer\n",
      "addr_state                      AZ\n",
      "earliest_cr_line          Jan-1985\n",
      "revol_util                   83.7%\n",
      "last_credit_pull_d        Jun-2016\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "objects=loans.select_dtypes(include=['object'])\n",
    "print(objects.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column home_ownership\n",
      "RENT        19303\n",
      "MORTGAGE    17883\n",
      "OWN          2951\n",
      "OTHER         134\n",
      "NONE            2\n",
      "Name: home_ownership, dtype: int64\n",
      "======================================================\n",
      "Column verification_status\n",
      "Not Verified       17978\n",
      "Verified           12471\n",
      "Source Verified     9824\n",
      "Name: verification_status, dtype: int64\n",
      "======================================================\n",
      "Column emp_length\n",
      "10+ years    9003\n",
      "< 1 year     4940\n",
      "2 years      4641\n",
      "3 years      4282\n",
      "4 years      3551\n",
      "1 year       3503\n",
      "5 years      3372\n",
      "6 years      2318\n",
      "7 years      1811\n",
      "8 years      1546\n",
      "9 years      1306\n",
      "Name: emp_length, dtype: int64\n",
      "======================================================\n",
      "Column term\n",
      " 36 months    30530\n",
      " 60 months     9743\n",
      "Name: term, dtype: int64\n",
      "======================================================\n",
      "Column addr_state\n",
      "CA    7096\n",
      "NY    3839\n",
      "FL    2917\n",
      "TX    2788\n",
      "NJ    1903\n",
      "IL    1591\n",
      "PA    1571\n",
      "VA    1423\n",
      "GA    1419\n",
      "MA    1345\n",
      "OH    1250\n",
      "MD    1076\n",
      "AZ     856\n",
      "WA     833\n",
      "CO     808\n",
      "CT     767\n",
      "NC     765\n",
      "MI     751\n",
      "MO     721\n",
      "MN     616\n",
      "NV     494\n",
      "WI     475\n",
      "SC     471\n",
      "AL     451\n",
      "LA     444\n",
      "OR     438\n",
      "KY     341\n",
      "OK     302\n",
      "KS     274\n",
      "UT     267\n",
      "AR     244\n",
      "DC     219\n",
      "RI     203\n",
      "NM     195\n",
      "WV     173\n",
      "NH     173\n",
      "HI     169\n",
      "DE     132\n",
      "MT      87\n",
      "AK      81\n",
      "WY      79\n",
      "SD      63\n",
      "VT      56\n",
      "TN      32\n",
      "MS      26\n",
      "IN      15\n",
      "IA      12\n",
      "NE      11\n",
      "ID       9\n",
      "ME       2\n",
      "Name: addr_state, dtype: int64\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "cols= [ 'home_ownership', 'verification_status', 'emp_length','term','addr_state']\n",
    "for c in cols:\n",
    "    print('Column',c)\n",
    "    print(loans[c].value_counts())\n",
    "    print('======================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I counted the number of each value for the columns below: \n",
    "<br>\n",
    "['home_ownership', 'verification_status', 'emp_length', 'term', 'addr_state'] \n",
    "<br>\n",
    "I will develop strategies to change data types while using these counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debt Consolidation                2134\n",
      "Debt Consolidation Loan           1625\n",
      "Personal Loan                      669\n",
      "Consolidation                      517\n",
      "debt consolidation                 489\n",
      "                                  ... \n",
      "Credit Card repayments               1\n",
      "Florida June 2011                    1\n",
      "Payoff Prior Lending Club loan       1\n",
      "franis loan                          1\n",
      "Discover Obliteration                1\n",
      "Name: title, Length: 20420, dtype: int64\n",
      "====================================================================\n",
      "debt_consolidation    18813\n",
      "credit_card            5224\n",
      "other                  4092\n",
      "home_improvement       3013\n",
      "major_purchase         2204\n",
      "small_business         1875\n",
      "car                    1520\n",
      "wedding                 972\n",
      "medical                 711\n",
      "moving                  593\n",
      "educational             400\n",
      "house                   397\n",
      "vacation                362\n",
      "renewable_energy         97\n",
      "Name: purpose, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(loans['title'].value_counts())\n",
    "print('====================================================================')\n",
    "print(loans['purpose'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will use mapping method to encode the 'emp_length' column.\n",
    "mapping= {\n",
    "    'emp_length':{\n",
    "        '10+ years': 10,\n",
    "        '9 years': 9,\n",
    "        '8 years': 8,\n",
    "        '7 years': 7,\n",
    "        '6 years': 6,\n",
    "        '5 years': 5,\n",
    "        '1 year': 1,\n",
    "        '4 years': 4,\n",
    "        '3 years': 3,\n",
    "        '2 years': 2,\n",
    "        '< 1 year': 0,\n",
    "        'n/a': 0\n",
    " \n",
    "    }\n",
    "}\n",
    "\n",
    "loans= loans.replace(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40273 entries, 0 to 42478\n",
      "Data columns (total 25 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   loan_amnt            40273 non-null  float64\n",
      " 1   term                 40273 non-null  object \n",
      " 2   int_rate             40273 non-null  object \n",
      " 3   installment          40273 non-null  float64\n",
      " 4   emp_length           40273 non-null  int64  \n",
      " 5   home_ownership       40273 non-null  object \n",
      " 6   annual_inc           40273 non-null  float64\n",
      " 7   verification_status  40273 non-null  object \n",
      " 8   loan_status          40273 non-null  int64  \n",
      " 9   purpose              40273 non-null  object \n",
      " 10  title                40273 non-null  object \n",
      " 11  addr_state           40273 non-null  object \n",
      " 12  dti                  40273 non-null  float64\n",
      " 13  delinq_2yrs          40273 non-null  float64\n",
      " 14  earliest_cr_line     40273 non-null  object \n",
      " 15  inq_last_6mths       40273 non-null  float64\n",
      " 16  open_acc             40273 non-null  float64\n",
      " 17  pub_rec              40273 non-null  float64\n",
      " 18  revol_bal            40273 non-null  float64\n",
      " 19  revol_util           40273 non-null  object \n",
      " 20  total_acc            40273 non-null  float64\n",
      " 21  last_credit_pull_d   40273 non-null  object \n",
      " 22  acc_now_delinq       40273 non-null  float64\n",
      " 23  delinq_amnt          40273 non-null  float64\n",
      " 24  tax_liens            40273 non-null  float64\n",
      "dtypes: float64(13), int64(2), object(10)\n",
      "memory usage: 8.0+ MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will drop some columns again.\n",
    "loans= loans.drop(['title', 'addr_state','earliest_cr_line','last_credit_pull_d'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped the columns above because they have a lot of unique values, and they are not useful with these unique entries for my prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will clean \"%\" character from two columns.\n",
    "loans['int_rate']= loans['int_rate'].str.rstrip('%').astype('float')\n",
    "loans['revol_util']= loans['revol_util'].str.rstrip('%').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will encode the columns which are in the list below.\n",
    "cat_columns=['home_ownership','verification_status','purpose','term']\n",
    "dummy_df= pd.get_dummies(loans[cat_columns])\n",
    "loans= pd.concat([loans,dummy_df], axis=1)\n",
    "loans= loans.drop(cat_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40273 entries, 0 to 42478\n",
      "Data columns (total 41 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   loan_amnt                            40273 non-null  float64\n",
      " 1   int_rate                             40273 non-null  float64\n",
      " 2   installment                          40273 non-null  float64\n",
      " 3   emp_length                           40273 non-null  int64  \n",
      " 4   annual_inc                           40273 non-null  float64\n",
      " 5   loan_status                          40273 non-null  int64  \n",
      " 6   dti                                  40273 non-null  float64\n",
      " 7   delinq_2yrs                          40273 non-null  float64\n",
      " 8   inq_last_6mths                       40273 non-null  float64\n",
      " 9   open_acc                             40273 non-null  float64\n",
      " 10  pub_rec                              40273 non-null  float64\n",
      " 11  revol_bal                            40273 non-null  float64\n",
      " 12  revol_util                           40273 non-null  float64\n",
      " 13  total_acc                            40273 non-null  float64\n",
      " 14  acc_now_delinq                       40273 non-null  float64\n",
      " 15  delinq_amnt                          40273 non-null  float64\n",
      " 16  tax_liens                            40273 non-null  float64\n",
      " 17  home_ownership_MORTGAGE              40273 non-null  uint8  \n",
      " 18  home_ownership_NONE                  40273 non-null  uint8  \n",
      " 19  home_ownership_OTHER                 40273 non-null  uint8  \n",
      " 20  home_ownership_OWN                   40273 non-null  uint8  \n",
      " 21  home_ownership_RENT                  40273 non-null  uint8  \n",
      " 22  verification_status_Not Verified     40273 non-null  uint8  \n",
      " 23  verification_status_Source Verified  40273 non-null  uint8  \n",
      " 24  verification_status_Verified         40273 non-null  uint8  \n",
      " 25  purpose_car                          40273 non-null  uint8  \n",
      " 26  purpose_credit_card                  40273 non-null  uint8  \n",
      " 27  purpose_debt_consolidation           40273 non-null  uint8  \n",
      " 28  purpose_educational                  40273 non-null  uint8  \n",
      " 29  purpose_home_improvement             40273 non-null  uint8  \n",
      " 30  purpose_house                        40273 non-null  uint8  \n",
      " 31  purpose_major_purchase               40273 non-null  uint8  \n",
      " 32  purpose_medical                      40273 non-null  uint8  \n",
      " 33  purpose_moving                       40273 non-null  uint8  \n",
      " 34  purpose_other                        40273 non-null  uint8  \n",
      " 35  purpose_renewable_energy             40273 non-null  uint8  \n",
      " 36  purpose_small_business               40273 non-null  uint8  \n",
      " 37  purpose_vacation                     40273 non-null  uint8  \n",
      " 38  purpose_wedding                      40273 non-null  uint8  \n",
      " 39  term_ 36 months                      40273 non-null  uint8  \n",
      " 40  term_ 60 months                      40273 non-null  uint8  \n",
      "dtypes: float64(15), int64(2), uint8(24)\n",
      "memory usage: 6.5 MB\n"
     ]
    }
   ],
   "source": [
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I have 38 columns and 40273 entries to use. They are numerical values right now. I created my features and I can proceed to the prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    40272\n",
       "1.0        1\n",
       "Name: tax_liens, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans['tax_liens'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use FPR and TPR metrics to observe my model's success because my data is inbalanced. I want to get money. I do not want to give money to the wrong person. If I give money to the wrong person, we will lose money. So, my TPR and FPR values should be low on the test process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will select train and test data to create prediction model.\n",
    "cols=loans.columns\n",
    "train_cols= cols.drop('loan_status')\n",
    "x=loans[train_cols]\n",
    "y= loans['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(x,y,test_size=0.3,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    23865\n",
       "0     4326\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10288\n",
       "0     1794\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I splitted the data as train and test. I will create prediction models and test these models on the train and test data sets. Let's start with a basic pandas prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions= pd.Series(np.ones(loans.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (loans['loan_status']==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(loans['loan_status']==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (loans['loan_status']==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (loans['loan_status']==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0],\n",
       "       [ 6120, 34153]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,loans['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    40273\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I expected, I have gotten FPR and TPR values as 1. This is the situation that I do not want. In this step, I will use random forest classifier algorithm to create my prediction model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x_train,y_train)\n",
    "predictions= rf.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0002311604253351826\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4325,     0],\n",
       "       [    1, 23865]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9966951788491446\n",
      "0.9782608695652174\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   39,    34],\n",
       "       [ 1755, 10254]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have obtained high TPR and FPR values on the test data again. I will make another prediction with cross validation and see the results on train data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=cross_val_predict(rf, x_train, y_train, cv=10)\n",
    "predictions= pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9944882394411331\n",
      "0.9941456275155507\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   68,    97],\n",
       "       [ 4258, 23768]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained high TPR and FPR values again. I will set the \"class_weight\" parameter as balanced. After that, I will check FPR and TPR values on test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(class_weight='balanced', random_state=101)\n",
    "predictions=cross_val_predict(rf, x_train, y_train, cv=10)\n",
    "predictions= pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967313978081138\n",
      "0.9948774240761068\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   48,    51],\n",
       "       [ 4278, 23814]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x_train,y_train)\n",
    "predictions= rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9981531881804043\n",
      "0.9905239687848384\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   17,    19],\n",
       "       [ 1777, 10269]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need more improvement on the model. I will set the \"class_weight\" parameter as penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty= {\n",
    "    0:12,\n",
    "    1:1\n",
    "}\n",
    "rf= RandomForestClassifier(class_weight=penalty)\n",
    "predictions= cross_val_predict(rf,x_train,y_train, cv=15)\n",
    "predictions=pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9978850221111325\n",
      "0.9978046103183315\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   35,    32],\n",
       "       [ 4291, 23833]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(x_train,y_train)\n",
    "predictions= rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9975699844479005\n",
      "0.9933110367892977\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   12,    25],\n",
       "       [ 1782, 10263]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the \"class_weight\" parameter as penalty but I could not be successful to reduce the FPR and TPR values. I want to use logistic regression algorithm because random forest classifier is not successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "predictions= lr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989105384454222\n",
      "0.9976883957466481\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   10,    26],\n",
       "       [ 4316, 23839]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988335925349923\n",
      "0.9972129319955407\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    5,    12],\n",
       "       [ 1789, 10276]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have obtained high FPR and TPR values for the test and train data, again. I will work with cross validation to see the prediction results for the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= cross_val_predict(lr,x_train,y_train,cv=3)\n",
    "predictions=pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9987822854579248\n",
      "0.9985364068788877\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   11,    31],\n",
       "       [ 4315, 23834]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I still have obtained high results. After this step, I will work on the \"class_weight\" parameter while setting it as balanced or penalty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr= LogisticRegression(class_weight= 'balanced')\n",
    "predictions= cross_val_predict(lr, x_train, y_train, cv=3)\n",
    "predictions= pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49881433057745306\n",
      "0.5042078302231979\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2891, 11334],\n",
       "       [ 1435, 12531]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "predictions= lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5486003110419907\n",
      "0.3701226309921962\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1130, 4644],\n",
       "       [ 664, 5644]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have succeeded to reduce almost half the TPR and FPR values for the train and test data sets. It is really good development for me. On the train data set, I have obtained the TPR value as %49 and the FPR value as %50, and I have predicted 2891 delinquent borrowers and 11334 paid borrowers on the train data, succesfully. On the test data set, I have obtained the TPR value as %54 and the FPR value as %37. According to confusion matrix, I have achieved to predict 1130 delinquent borrowers and 4644 paid borrowers on the test data. Still, I need more work on the prediction model. So, I will set the \"class_weight\" parameter as penalty and I will make changes on the penalty factor to find proper results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start with setting the delinquent borrower(0) factor with 15 and paid borrower(1) factor as 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "penalty= {\n",
    "    0:15,\n",
    "    1:1.5\n",
    "}\n",
    "lr= LogisticRegression(class_weight=penalty, C=0.01)\n",
    "predictions= cross_val_predict(lr,x_train,y_train, cv=15)\n",
    "predictions=pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10760751137601743\n",
      "0.11525795828759605\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4131, 21036],\n",
       "       [  195,  2829]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "predictions= lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1786547433903577\n",
      "0.07357859531772576\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1662, 8450],\n",
       "       [ 132, 1838]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have accomplished to greatly reduce the FPR and TPR values for two of the data sets. For the test data set, I have gotten the TPR value as %17 and the FPR value as %7. According to confusion matrix, I have successfully predicted 1662 delinquent borrowers and 8450 paid borrowers. Now, I will set the delinquent borrower(0) factor with 12 and paid borrower(1) factor as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "penalty= {\n",
    "    0:12,\n",
    "    1:1\n",
    "}\n",
    "lr= LogisticRegression(class_weight=penalty, C=0.01)\n",
    "predictions= cross_val_predict(lr,x_train,y_train, cv=15)\n",
    "predictions=pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.059796193039800036\n",
      "0.06622758873033296\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4240, 22246],\n",
       "       [   86,  1619]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "predictions= lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07124805598755832\n",
      "0.023968784838350056\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1751, 9555],\n",
       "       [  43,  733]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With new implemention, I have had the FPR value as %2 and the TPR value as %7. It is really good result, but I want to get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "penalty= {\n",
    "    0:10.5,\n",
    "    1:0.75\n",
    "}\n",
    "lr= LogisticRegression(class_weight=penalty, C=0.01)\n",
    "predictions= cross_val_predict(lr,x_train,y_train, cv=15)\n",
    "predictions=pd.Series(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02095750817150548\n",
      "0.018660812294182216\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_train==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_train==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_train==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_train==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4278, 23327],\n",
       "       [   48,   538]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suheylakiymaci/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "predictions= lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03411741835147745\n",
      "0.006131549609810479\n"
     ]
    }
   ],
   "source": [
    "fp_filter= (predictions==1)& (y_test==0)\n",
    "fp= len(predictions[fp_filter])\n",
    "tp_filter= (predictions==1)&(y_test==1)\n",
    "tp= len(predictions[tp_filter])\n",
    "fn_filter= (predictions==0)& (y_test==1)\n",
    "fn= len(predictions[fn_filter])\n",
    "tn_filter= (predictions==0)& (y_test==0)\n",
    "tn= len(predictions[tn_filter])\n",
    "\n",
    "tpr=tp/(tp+fn)\n",
    "fpr= fp/(fp+tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1783, 9937],\n",
       "       [  11,  351]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have obtained the most successful result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have had the most successful results with logistic regression algorithm. I set the \"class_weight\" parameter as penalty. I set the 0(False) with 10.5 factor and 1(True) with 0.75 factor. I have obtained the TPR value as %2 and the FPR value as %1 on the train data set. According to results of the confusion matrix, I achieved to predict 4278 delinquents from 4326 and 23327 paid borrowers from 23865. Also, I have gotten the TPR value as %3 and the FPR value as %1 on the test data set. The outcome of the confusion matrix shows that, I have successfully predicted 1783 delinquents from 1794 and 9937 paid borrowers from 1288 paid borrowers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
